搜索引擎大致可以分为四个部分：搜集、分析、索引、查询。
搜集，就是我们常说的利用爬虫爬取网页。
分析，主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作。
索引，主要负责通过分析阶段得到的临时索引，构建倒排索引。
查询，主要负责响应用户的请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。

一.搜索
搜索引擎把整个互联网看作数据结构中的有向图，把每个页面看作一个顶点。
如果某个页面中包含另外一个页面的链接，那我们就在两个顶点之间连一条有向边。我们可以利用图的遍历搜索算法，来遍历整个互联网中的网页。
我们可以利用图的遍历搜索算法，来遍历整个互联网中的网页。
搜索引擎采用的是广度优先搜索策略。具体点讲的话，那就是，我们先找一些比较知名的网页（专业的叫法是权重比较高）的链接（比如新浪主页网址、腾讯主页网址等），作为种子网页链接，放入到队列中。
1. 待爬取网页链接文件：links.bin
2. 网页判重文件：bloom_filter.bin
3. 原始网页存储文件：doc_raw.bin
4. 网页链接及其编号的对应文件：doc_id.bin

二.分析
1. 抽取网页文本信息
第一步是去掉 JavaScript 代码、CSS 格式以及下拉框中的内容（因为下拉框在用户不操作的情况下，也是看不到的）。
也就是<style></style>，<script></script>，<option></option>这三组标签之间的内容。
我们可以利用 AC 自动机这种多模式串匹配算法，在网页这个大字符串中，一次性查找<style>, <script>, <option>这三个关键词。
当找到某个关键词出现的位置之后，我们只需要依次往后遍历，直到对应结束标签（</style>, </script>, </option）为止。而这期间遍历到的字符串连带着标签就应该从网页中删除。
第二步是去掉所有 HTML 标签。这一步也是通过字符串匹配算法来实现的。过程跟第一步类似，我就不重复讲了。
2. 分词并创建临时索引
对于英文网页来说，分词非常简单。我们只需要通过空格、标点符号等分隔符，将每个单词分割开来就可以了。
但是，对于中文来说，分词就复杂太多了。我这里介绍一种比较简单的思路，基于字典和规则的分词方法。









